---
title: "DualPAMImportData"
author:
- Julie A. Nadeau
- Mireille Savoie
- Douglas A. Campbell
date: "`r format(Sys.Date())`"
output:
  html_document:
    df_print: paged
    code_folding: hide
    keep_md: yes
    fig_caption: yes
    toc: TRUE
    toc_float: TRUE   
csl: plos-one.csl
---

This .Rmd imports and tidys underlying data from the DualPAM kinetic fluorometer/absorbtometer software, along with culture MetaData and Turner Chlorophyll data. 

# Set Chunk Options

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
knitr::opts_chunk$set(fig.path='Figs/')
```

# Set Project Variables

```{r set project variables}
Project <- "PICO"
DataOut <- file.path("..", "Data", "ProcessedData")

Run <- "O2Analyses"

#ExpDate <- "2023-05-27" #date of first MultiCulti growth start

DataIn <- file.path("..", "Data", "RawData", "DualPAM", "Report", fsep = .Platform$file.sep)

FileID <- ".csv"

Catalog <- "https://docs.google.com/spreadsheets/d/1ZXpwR7Gfto-uRzVdXzMpQF4frbrvMLH_IyLqonFZRSw/edit#gid=0"
# 
# ChlTurner <- "https://docs.google.com/spreadsheets/d/13mQm0B3siS65UuGjNdzvpHFomfuwn6aAg7dBoq1IqrM/edit#gid=0"

FileEncode <- "UTF-8" 
Delimiter <- ";"

#number of rows in each individual run, including Fo, Fm & 12 actinic light levels
#no longer necessary
#LightSteps <- 15

#TempCont <- "TC"

NoO2Runs <- c("JuNa1201", "JuNa1202", "JuNa1203", "JuNa1204", "JuNa1205")
BadRuns <- c("JuNa1215")
DubiousRuns <- c("JuNa1206", "JuNa1207", "JuNa1208", "JuNa1209", "JuNa1210")


```

```{r conversions}
us_s <- 1000000
photons_umol <- 6.022E17
A2_m2 <- 1E20
```

```{r load libraries}
library(tidyverse)
library(lubridate)
library(photobiologyWavebands) #R colours from nm values
library(broom) #formatting model outputs

#https://googlesheets4.tidyverse.org/
library(googledrive)
library(googlesheets4)

```

Load Multiculti catalog
Note: Added 'SampleID' column to googlesheet b/c ID numbers overlap with earlier samples
Note: Add Chl data to MultiCulti Catalog; Julie
```{r load multiculticatalog, message = FALSE, warning = FALSE, echo=FALSE}
gs4_deauth()

#Increase guess_max to catch character codes in SampleID
MetaData <- read_sheet(Catalog, guess_max = 2000) |>
  drop_na(WL) |>
  mutate(WL = unlist(WL)) |>
  filter(!is.na(SampleID))

as.data.frame(MetaData)

MetaData <- MetaData %>%
   mutate(ExpDate = lubridate::ymd(ExpDate),
          ExpEndDate = lubridate::ymd_hms(`ExpEndDate`)) |>
  select(-c("Description", "Motivation", "doi", "Par_ueAdjusted", "DateOfAdjustment", "ElaspedHoursAtAdjustment" )) 



```

```{r set colours}
Wavelengths_nm = c(445, 470, 505, 535, 590)
Colours_nm = c(w_length2rgb(Wavelengths_nm[1]), w_length2rgb(Wavelengths_nm[2]), w_length2rgb(Wavelengths_nm[3]), w_length2rgb(Wavelengths_nm[4]), w_length2rgb(Wavelengths_nm[5]))

names(Colours_nm) <- Wavelengths_nm
Colours_nm

```

```{r list DualPAM Report files for file import}
DualPAMFiles <- list.files(path = DataIn, pattern = FileID, full.names = TRUE, recursive = FALSE)

DualPAMFiles

#test for duplicate file names
unique(duplicated(DualPAMFiles))
```

```{r data read adds filename and cdate, warning=FALSE, message=FALSE, echo=FALSE}

#a read function using tidyverse::read_delim that skips a fixed number of header rows, and adds columns to the dataframe containing the filename and the file creation date time.
read_delim_plus <- function(flnm, delimiter, headerrows, fileencode){read_delim(flnm, delim = delimiter,  col_names = TRUE,  skip = headerrows, escape_double = FALSE,  locale = locale(encoding = fileencode), trim_ws = TRUE) %>%
    mutate(Filename = flnm)
}

```

Read Test File
DualPAM data is appending desired RLC data to previously captured data.
Need to select final XX rows of each file to get the 'last' captured RLC, b/c as runs accumulate, saved files increase in length/rows.

```{r read and tidy function}
# read_delim_DualPAM <- function(flnm, delimiter, headerrows, fileencode){read_delim_plus(flnm, delimiter = Delimiter, headerrows = DataHeaderRows, fileencode = FileEncode) |>
#     slice_tail(n = LightSteps) |>
#     select(-c(`k/ocs`, `F(I)/Fo calc`, `FMTm`, `F/Fm`,`Fm'/Fm`, `Y(4S)`, `...32`)) |>
#     filter(Action != c("LC-Start", "Manual", "LC-Stop")) |>
#     rename(FI = `F(I)`,
#          Fo = `Fo,Fo'`,
#          Fm = `Fm,Fm'`,
#          YII = `Y(II)`,
#          ETRII = `ETR(II)`,
#          YNO = `Y(NO)`,
#          YNPQ = `Y(NPQ)`,
#          P700m = `P700m,P700m'`,
#          YI = `Y(I)`,
#          YND = `Y(ND)`,
#          YNA = `Y(NA)`,
#          ETRI = `ETR(I)`) |>
#     type_convert() |>
#     mutate(Filename = str_remove(Filename, pattern = "../Data/RawData/DualPAM/Report/")) |>
#     mutate(Filename = str_remove(Filename, pattern = ".csv")) |>
#     separate_wider_delim(Filename, delim = "_",  names = c("RunDateTime", "Project", "SampleID", "MeasureO2_uM"), cols_remove = FALSE) |>
#     mutate(RunDateTime = ymd_hm(RunDateTime)) 
# }

read_delim_DualPAM <- function(flnm, delimiter, headerrows, fileencode){DataFile <- read_delim_plus(flnm, delimiter = Delimiter, headerrows = DataHeaderRows, fileencode = FileEncode)
  
 LRCMaxRow <-  (max(which(DataFile$Action == "LC-Start")) - 1)
  
  DataFile <- DataFile |>
    slice_tail(n = -LRCMaxRow) |>
    select(-c(`k/ocs`, `F(I)/Fo calc`, `FMTm`, `F/Fm`,`Fm'/Fm`, `Y(4S)`, `...32`)) |>
    filter(!(Action %in% c("LC-Start", "Manual", "LC-Stop"))) |>
    rename(FI = `F(I)`,
         Fo = `Fo,Fo'`,
         Fm = `Fm,Fm'`,
         YII = `Y(II)`,
         ETRII = `ETR(II)`,
         YNO = `Y(NO)`,
         YNPQ = `Y(NPQ)`,
         P700m = `P700m,P700m'`,
         YI = `Y(I)`,
         YND = `Y(ND)`,
         YNA = `Y(NA)`,
         ETRI = `ETR(I)`) |>
    type_convert() |>
    mutate(Filename = str_remove(Filename, pattern = "../Data/RawData/DualPAM/Report/")) |>
    mutate(Filename = str_remove(Filename, pattern = ".csv")) |>
    separate_wider_delim(Filename, delim = "_",  names = c("RunDateTime", "Project", "SampleID", "MeasureO2_uM"), cols_remove = FALSE) |>
    mutate(RunDateTime = ymd_hm(RunDateTime)) 
  DataFile
}


```


```{r read example DualPAMData file onestep}
# DataHeaderRows <- 0
# 
# DualPAMOneStep <- read_delim_DualPAM(flnm = "../Data/RawData/DualPAM/Report/202311151130_PICO_JuNa1249_250.csv", delimiter = Delimiter, headerrows = DataHeaderRows, fileencode = FileEncode)



```

purrr::map to read all files, onestep read and tidy read_delim_DualPAM function

```{r read DualPAM files}
DataHeaderRows <- 0

DualPAMData <- DualPAMFiles |>
  map_df(~ read_delim_DualPAM(flnm =., delimiter = Delimiter, headerrows = DataHeaderRows, fileencode = FileEncode))

DualPAMData |>
  mutate(MeasureO2_uM = as.numeric(MeasureO2_uM))

head(DualPAMData)
colnames(DualPAMData)
length(unique(DualPAMData$Filename))
```

```{r DualPAMData plot}
DualPAMData |>
  ggplot() +
  geom_point(aes(x = PAR, y = YI), colour = "blue") +
  geom_point(aes(x = PAR, y = YII), colour = "red") +
  facet_grid(cols = vars(MeasureO2_uM), rows = vars(SampleID)) +
  theme_bw()

DualPAMData|>
  filter(MeasureO2_uM %in% c(2, 25, 250)) |>
  filter(!(SampleID %in% c("JuNa1201", "JuNa1202", "JuNa1203", "JuNa1204", "JuNa1205"))) |>
  #filter(SampleID %in% c("JuNa1216","JuNa1220","JuNa1221","JuNa1219","JuNa1222","JuNa1217","JuNa1218","JuNa1231","JuNa1230","JuNa1229")) |>
  ggplot() +
  geom_point(aes(x = PAR, y = YI), colour = "blue") +
  geom_point(aes(x = PAR, y = YII), colour = "red") +
  facet_grid(cols = vars(MeasureO2_uM), rows = vars(SampleID)) +
  theme_bw()

DualPAMData |>
  filter(MeasureO2_uM %in% c(2, 25, 250)) |>
  ggplot() +
  geom_point(aes(x = YII, y = YI)) +
  facet_grid(cols = vars(MeasureO2_uM), rows = vars(SampleID)) +
  theme_bw()

```

# Merge with MetaData & Chl Data

```{r merge with metadata}
DualPAMMeta <- left_join(x = DualPAMData, y = MetaData, join_by("SampleID" == "SampleID"))


# SolDataMeta <- left_join(x = SolDataMeta, y = ChlData, join_by("SampleID" == "SampleID"))

```


```{r DualPAMData plot}


DualPAMMeta |>
  #filter(Strain == "PCC9511") |>
  # filter(Par_ue == 30) |>
  # filter(O2 == 21) |>
  ggplot() +
  geom_point(aes(x = PAR, y = YI), colour = "blue") +
  geom_point(aes(x = PAR, y = YII), colour = "red") +
  facet_grid(cols = vars(MeasureO2_uM), rows = vars(Strain, SampleID)) +
  theme_bw()

DualPAMMeta |>
  filter(MeasureO2_uM %in% c(2, 25, 250)) |>
  filter(!(SampleID %in% NoO2Runs)) |>
  filter(!SampleID %in% BadRuns) |>
  filter(OptodeMeasure == 1) |>
  filter(Strain == "PCC9511") |>
  ggplot() +
  geom_point(aes(x = PAR, y = YI), colour = "blue") +
  geom_point(aes(x = PAR, y = YII), colour = "red") +
  facet_grid(cols = vars(MeasureO2_uM), rows = vars(Strain, Par_ue, O2_Category)) +
  theme_bw()

DualPAMMeta |>
  filter(MeasureO2_uM %in% c(2, 25, 250)) |>
  filter(!(SampleID %in% NoO2Runs)) |>
  filter(!SampleID %in% BadRuns) |>
  filter(OptodeMeasure == 1) |>
  filter(Strain == "MIT9313") |>
  ggplot() +
  geom_point(aes(x = PAR, y = YI), colour = "blue") +
  geom_point(aes(x = PAR, y = YII), colour = "red") +
  facet_grid(cols = vars(MeasureO2_uM), rows = vars(Strain, Par_ue, O2_Category)) +
  theme_bw()

DualPAMMeta |>
  filter(MeasureO2_uM %in% c(2, 25, 250)) |>
  filter(!(SampleID %in% NoO2Runs)) |>
  filter(!SampleID %in% BadRuns) |>
    filter(Strain == "PCC9511") |>
    filter(OptodeMeasure == 1) |>
  ggplot() +
  geom_point(aes(x = YI, y = YII, colour = as.factor(OptodeMeasure))) +
  #geom_smooth(aes(x = YI, y = YII), method = "lm") +
  facet_grid(cols = vars(MeasureO2_uM), rows = vars(Strain, Par_ue, O2_Category)) +
  theme_bw()

DualPAMMeta |>
  filter(MeasureO2_uM %in% c(2, 25, 250)) |>
  filter(!(SampleID %in% NoO2Runs)) |>
  filter(!SampleID %in% BadRuns) |>
    filter(Strain == "MIT9313") |>
    filter(OptodeMeasure == 1) |>
  ggplot() +
  geom_point(aes(x = YI, y = YII, colour = as.factor(OptodeMeasure))) +
  #geom_smooth(aes(x = YI, y = YII), method = "lm") +
  facet_grid(cols = vars(MeasureO2_uM), rows = vars(Strain, Par_ue, O2_Category)) +
  theme_bw()

```
```{r save DualPAMMeta}
 saveRDS(DualPAMMeta, file.path(DataOut, paste(Project, Run, "DualPAMMeta.Rds", sep = "_"), fsep = .Platform$file.sep))
```

Self Starting Exponential Decay Function
https://douglas-watson.github.io/post/2018-09_exponential_curve_fitting/

```{r fit self starting exponential decay}
YFits <-   DualPAMMeta |>
  filter(MeasureO2_uM %in% c(2, 25, 250)) |>
  filter(!(SampleID %in% NoO2Runs)) |>
  filter(!SampleID %in% BadRuns) |>
  filter(OptodeMeasure == 1) |>
  nest(data = -c(Strain, O2_Category, MeasureO2_uM)) %>%
  mutate(
    YIfit = map(data, ~nls(YI ~ SSasymp(PAR, YIf, YI0, log_alpha), data = .)),
    YItidied = map(YIfit, tidy),
    YIaugmented = map(YIfit, augment),
  ) |>
mutate(
    YIIfit = map(data, ~nls(YII ~ SSasymp(PAR, YIIf, YII0, log_alpha), data = .)),
    YIItidied = map(YIIfit, tidy),
    YIIaugmented = map(YIIfit, augment),
  )  

YFits

YIFitValues <- YFits |>
  unnest(YItidied) |>
  select(Strain, O2_Category, MeasureO2_uM, term, estimate, std.error) |> 
  pivot_wider(names_from = c(term), values_from = c(estimate, std.error)) |>
  mutate(alpha = exp(estimate_log_alpha),
         alpha_se = exp(std.error_log_alpha))

YIFitValues <- YFits |>
  unnest_cross(YItidied) |>
  select(Strain, O2_Category, MeasureO2_uM, term, estimate, std.error) |> 
  pivot_wider(names_from = c(term), values_from = c(estimate, std.error)) |>
  mutate(alpha = exp(estimate_log_alpha),
         alpha_se = exp(std.error_log_alpha))
```

