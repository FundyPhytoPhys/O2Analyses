---
title: "DualPAMImportData"
author:
- Julie A. Nadeau
- Mireille Savoie
- Douglas A. Campbell
date: "`r format(Sys.Date())`"
output:
  html_document:
    df_print: paged
    code_folding: hide
    keep_md: yes
    fig_caption: yes
    toc: TRUE
    toc_float: TRUE   
csl: plos-one.csl
---

This .Rmd imports and tidys underlying data from the DualPAM kinetic fluorometer/absorbtometer software, along with culture MetaData and Turner Chlorophyll data. 

# Set Chunk Options

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
knitr::opts_chunk$set(fig.path='Figs/')
```

# Set Project Variables

```{r set project variables}
Project <- "PICO"
DataOut <- file.path("..", "Data", "ProcessedData")

Run <- "O2Analyses"

#ExpDate <- "2023-05-27" #date of first MultiCulti growth start

DataIn <- file.path("..", "Data", "RawData", "DualPAM", "SP_Kinetics", fsep = .Platform$file.sep)

FileID <- ".CSV"

Catalog <- "https://docs.google.com/spreadsheets/d/1ZXpwR7Gfto-uRzVdXzMpQF4frbrvMLH_IyLqonFZRSw/edit#gid=0"
# 
# ChlTurner <- "https://docs.google.com/spreadsheets/d/13mQm0B3siS65UuGjNdzvpHFomfuwn6aAg7dBoq1IqrM/edit#gid=0"

FileEncode <- "UTF-8" 
Delimiter <- ";"

#number of rows in each individual run, including Fo, Fm & 12 actinic light levels
#no longer necessary
#LightSteps <- 15

#TempCont <- "TC"

NoO2Runs <- c("JuNa1201", "JuNa1202", "JuNa1203", "JuNa1204", "JuNa1205")
BadRuns <- c("JuNa1215")
DubiousRuns <- c("JuNa1206", "JuNa1207", "JuNa1208", "JuNa1209", "JuNa1210")


```

```{r conversions}
us_s <- 1000000
photons_umol <- 6.022E17
A2_m2 <- 1E20
```

```{r load libraries}
library(tidyverse)
library(lubridate)
#library(photobiologyWavebands) #R colours from nm values
library(broom) #formatting model outputs

#https://googlesheets4.tidyverse.org/
library(googledrive)
library(googlesheets4)

```

Load Multiculti catalog
Note: Added 'SampleID' column to googlesheet b/c ID numbers overlap with earlier samples
Note: Add Chl data to MultiCulti Catalog; Julie
```{r load multiculticatalog, message = FALSE, warning = FALSE, echo=FALSE}
gs4_deauth()

#Increase guess_max to catch character codes in SampleID
MetaData <- read_sheet(Catalog, guess_max = 2000) |>
  drop_na(WL) |>
  mutate(WL = unlist(WL)) |>
  filter(!is.na(SampleID))

as.data.frame(MetaData)

MetaData <- MetaData %>%
   mutate(ExpDate = lubridate::ymd(ExpDate),
          ExpEndDate = lubridate::ymd_hms(`ExpEndDate`)) |>
  select(-c("Description", "Motivation", "doi", "Par_ueAdjusted", "DateOfAdjustment", "ElaspedHoursAtAdjustment" )) 



```

```{r set colours}
# Wavelengths_nm = c(445, 470, 505, 535, 590)
# Colours_nm = c(w_length2rgb(Wavelengths_nm[1]), w_length2rgb(Wavelengths_nm[2]), w_length2rgb(Wavelengths_nm[3]), w_length2rgb(Wavelengths_nm[4]), w_length2rgb(Wavelengths_nm[5]))
# 
# names(Colours_nm) <- Wavelengths_nm
# Colours_nm

```

```{r list DualPAM Report files for file import}
DualPAMSPFiles <- list.files(path = DataIn, pattern = FileID, full.names = TRUE, recursive = TRUE, include.dirs = TRUE)

DualPAMSPFiles[1:20]

#test for duplicate file names
unique(duplicated(DualPAMSPFiles))


#Shrink by removing NoO2Runs and BadRuns
DualPAMSPFilterFiles <-DualPAMSPFiles[!DualPAMSPFiles %in% grep(paste0(c(NoO2Runs, BadRuns, DubiousRuns), collapse = "|"), DualPAMSPFiles, value = T)]
```

```{r data read adds filename and cdate, warning=FALSE, message=FALSE, echo=FALSE}

#a read function using tidyverse::read_delim that skips a fixed number of header rows, and adds columns to the dataframe containing the filename and the file creation date time.
# read_delim_plus <- function(flnm, delimiter, headerrows, fileencode){read_delim(flnm, delim = delimiter,  col_names = TRUE,  skip = headerrows, escape_double = FALSE,  locale = locale(encoding = fileencode), trim_ws = TRUE) %>%
#     mutate(Filename = flnm)
# }

```

Read Test File
DualPAM data is appending desired RLC data to previously captured data.
Need to select final XX rows of each file to get the 'last' captured RLC, b/c as runs accumulate, saved files increase in length/rows.

```{r read and tidy function}

DataHeaderRows <- 0

# SPOneStep <- read_delim(file =
# "../Data/RawData/DualPAM/SP_Kinetics/202311081023_PICO_JuNa1202_250/F_231108_101158_0.CSV", delim = Delimiter,  col_names = TRUE,  skip = DataHeaderRows,  locale=locale(encoding="latin1"))

#a read function using tidyverse::read_delim that skips a fixed number of header rows, and adds columns to the dataframe containing the filename and the file creation date time.
read_delim_plus_SP <- function(flnm, delimiter, headerrows){read_delim(flnm, delim = delimiter,  col_names = TRUE,  show_col_types = FALSE, skip = headerrows, locale=locale(encoding="latin1")) |>
    mutate(Filename = flnm) |>
    select(-c('...4')) |>
    rename(Time_ms = `time/ms`,
           Fluo_V = `Fluo/V`,
           P700delta = `P700 deltaI/I x10Â³`) 
}



# SPOneStep <- read_delim_plus_SP(flnm = "../Data/RawData/DualPAM/SP_Kinetics/202311081023_PICO_JuNa1202_250/F_231108_101158_0.CSV", delimiter = Delimiter, headerrows = DataHeaderRows)
# 
# 
# 
# |>
#   filter(!(SampleID %in% NoO2Runs)) |>
#   filter(!SampleID %in% BadRuns)
# 
#   str_remove(string = .$Filename, pattern = "../Data/RawData/DualPAM/SP_Kinetics/") |>

```

purrr::map to read all files, onestep read and tidy read_delim_DualPAM function

```{r read DualPAMSP files}
DataHeaderRows <- 0

#	../Data/RawData/DualPAM/SP_Kinetics/202311081615_PICO_JuNa1206_2/F_231108_163212_0.CSV
DualPAMSPData <- DualPAMSPFilterFiles |>
  map_df(~ read_delim_plus_SP(flnm =., delimiter = Delimiter, headerrows = DataHeaderRows)) |>
   mutate(Filename = str_remove(string = Filename, pattern = ".CSV")) |>
  mutate(Filename = str_remove(string = Filename, pattern = "../Data/RawData/DualPAM/SP_Kinetics/")) |>
  separate_wider_delim(cols = Filename, delim = "/", names = c("Sample", "Flash"), cols_remove = FALSE) |>
  separate_wider_delim(cols = Sample, delim = "_", names = c("DateTime", "Project", "SampleID", "MeasureO2_uM")) |>
  separate_wider_delim(cols = Flash, delim = "_", names = c("F", "Date", "MeasureTime", "Numeral")) |>
  mutate(DateTime = lubridate::ymd_hm(DateTime)) |>
  mutate(MeasureO2_uM = as.numeric(MeasureO2_uM)) |>
  mutate(MeasureTime = as.numeric(MeasureTime)) |>
  select(-c(F, Numeral))

head(DualPAMSPData, 20)
colnames(DualPAMSPData)
length(unique(DualPAMSPData$Filename))

```
Think about whether to include DateTime in grouping variable for normalization
```{r transforms}
#https://stackoverflow.com/questions/72991474/how-to-get-relative-rankings-of-numeric-elements-in-a-list-or-vector-in-r

DualPAMSPData <- DualPAMSPData |>
  #filter(SampleID == "JuNa1206") |>
  group_by(DateTime, Project, SampleID, MeasureO2_uM, Date) |>
  mutate(FlashTime = rank(MeasureTime, ties.method = "min")) |>
  mutate(FlashNum = dplyr::dense_rank(MeasureTime)) |>
  ungroup()

  
 #https://stackoverflow.com/questions/17619782/how-to-find-the-largest-n-elements-in-a-list-in-r
maxn <- function(x, n) {
  partial <- length(x) - n + 1
  x[x >= sort(x, partial = partial)[partial]]
}

  #Normalize signal to maximum for given filter
DualPAMSPData <- DualPAMSPData |>
  group_by(DateTime, Project, SampleID, Date) |>
  mutate(P700Norm = P700delta/mean(maxn(P700delta, 10))) |>
  mutate(FluoNorm = Fluo_V/mean(maxn(Fluo_V, 10))) |>
  ungroup()

  
head(DualPAMSPData)

unique(DualPAMSPData$FlashTime)
unique(DualPAMSPData$FlashNum)
unique(DualPAMSPData$SampleID)

#saveRDS(DualPAMSPData, file.path(DataOut, paste(Project, Run, "DualPAMSPData.Rds", sep = "_"), fsep = .Platform$file.sep))

```

```{r DualPAMData plot}
DualPAMSPData |>
  filter(SampleID == "JuNa1211") |>
  ggplot() +
  geom_point(aes(x = Time_ms, y = P700Norm), colour = "blue") +
  geom_point(aes(x = Time_ms, y = FluoNorm), colour = "red") +
  #facet_grid(rows = vars(MeasureO2_uM), cols = vars(FlashTime)) +
  theme_bw()

DualPAMSPData |>
  filter(SampleID == "JuNa1211") |>
  filter(FlashNum %in% c(2, 4, 6)) |>
  ggplot() +
  geom_point(aes(x = Time_ms, y = P700Norm), colour = "blue") +
  geom_point(aes(x = Time_ms, y = FluoNorm), colour = "red") +
  facet_grid(rows = vars(MeasureO2_uM), cols = vars(FlashNum)) +
  theme_bw()

DualPAMSPData |>
  filter(SampleID == "JuNa1211") |>
  filter(FlashNum %in% c(2, 4, 6)) |>
  ggplot() +
  geom_point(aes(x = FluoNorm, y = P700Norm, colour = Time_ms)) +
  facet_grid(rows = vars(MeasureO2_uM), cols = vars(FlashNum)) +
  theme_bw()
```


# Merge with MetaData & Chl Data
Files too big to handle; may need to subset
```{r merge with metadata}
DualPAMSPMeta <- left_join(x = DualPAMSPData, y = MetaData, join_by("SampleID" == "SampleID")) |>
  mutate(MeasureO2_uM = as.numeric(MeasureO2_uM)) |>
  select(-c(ID, Date, InnocDate, ExpDate, Inoc_mL, Media_mL, MediaDate, Plate, Well, EndDate, Salinity, Source, SourceSalinity, Optode, OptodeCh, InocpH, FinalpH, ExpEndDate, `...46`, `...47` ))


# SolDataMeta <- left_join(x = SolDataMeta, y = ChlData, join_by("SampleID" == "SampleID"))

head(DualPAMSPMeta)
```

```{r}
DualPAMSPMeta |>
  filter(Strain == "PCC9511") |>
  filter(O2_Category == "High") |>
  filter(Par_ue == "90") |>
  filter(FlashNum %in% c(2, 4, 6)) |>
  ggplot() +
  geom_point(aes(x = FluoNorm, y = P700Norm, colour = Time_ms)) +
  facet_grid(rows = vars(MeasureO2_uM), cols = vars(FlashNum)) +
  theme_bw()

DualPAMSPMeta |>
  filter(Strain == "MIT9313") |>
  filter(O2_Category == "High") |>
  filter(Par_ue == "30") |>
  filter(FlashNum %in% c(2, 4, 6,8,10)) |>
  ggplot() +
  geom_point(aes(x = FluoNorm, y = P700Norm, colour = Time_ms)) +
  facet_grid(rows = vars(MeasureO2_uM), cols = vars(FlashNum)) +
  theme_bw()
```

```{r save DualPAMPSMeta}
saveRDS(DualPAMSPMeta, file.path(DataOut, paste(Project, Run, "DualPAMSPMeta.Rds", sep = "_"), fsep = .Platform$file.sep))
```

